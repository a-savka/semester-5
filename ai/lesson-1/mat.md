# Математические основы в анализе данных (по материалам лекции)

В данном документе собрана и структурирована вся информация, озвученная на лекции и касающаяся математики, математической статистики и теории вероятностей, которые являются фундаментом для машинного обучения.

---

## 1. Зачем нужна математика в машинном обучении?

Лектор подчеркнул, что глубокое понимание математики необходимо специалисту по анализу данных для трех ключевых задач:

1.  **Выдвижение корректных гипотез:** Чтобы формулировать адекватные предположения о данных и взаимосвязях в них.
2.  **Выбор адекватных методов:** Чтобы осознанно выбирать правильные алгоритмы и техники для проверки гипотез и построения моделей.
3.  **Обоснование результатов:** Чтобы уметь доказывать состоятельность своих выводов на нескольких уровнях: математическом, статистическом и с точки зрения бизнес-логики.

Специалист по данным работает на стыке нескольких областей и должен уметь общаться на "языке" каждой из них.

---

## 2. Ключевые разделы математики и их применение

### А. Математический анализ
*   **Зачем нужен:** Для понимания поведения функций и их оптимизации.
*   **Ключевые темы:**
    *   Функции и их поведение
    *   Пределы и производные
    *   Основы интегрального исчисления (для оценки накопленных эффектов)
    *   Многомерные функции, частные производные и **градиент**.
*   **Практическое применение:** Процесс обучения нейронной сети — это, по сути, задача оптимизации. Мы пытаемся минимизировать **функцию ошибки**. Для этого используется метод **градиентного спуска**, который напрямую основан на понятии градиента из математического анализа.

### Б. Линейная алгебра
*   **Зачем нужна:** Лежит в основе всех современных алгоритмов обработки данных.
*   **Ключевые темы:**
    *   Операции с матрицами и векторами (скалярное и матричное умножение).
    *   Свойства матриц: транспонирование, ранг, определитель, обратная матрица.
    *   Понятия ортогональности и ортонормированности.
    *   **Собственные значения и собственные векторы**.
*   **Практическое применение:** Любые табличные данные в машинном обучении — это **матрица**. Методы понижения размерности, такие как **PCA (метод главных компонент)**, напрямую основаны на поиске собственных векторов и собственных значений матрицы ковариации признаков.

### В. Математическая статистика и теория вероятностей
*   **Зачем нужна:** Учит работать с неопределенностью и делать выводы на основе данных.
*   **Ключевые темы:**
    *   Описательная статистика: среднее, дисперсия, корреляция.
    *   Работа с вероятностями и распределениями.
    *   Разница между **выборкой** и **генеральной совокупностью**.
    *   Проверка гипотез.
*   **Практическое применение:** Статистика отвечает на важнейшие вопросы: Насколько надежны наши данные? Можем ли мы доверять выводам, сделанным на основе построенной модели? Есть ли статистически значимая связь между признаками?

---

## 3. Шкалы измерений и характеристики данных

Прежде чем применять математические методы, нужно понять тип данных, с которыми мы работаем. Для этого вводится понятие **шкал измерений**.

| Шкала | Описание | Примеры | Допустимые операции | Центральная тенденция | Разброс |
| :--- | :--- | :--- | :--- | :--- | :--- |
| **Номинальная** | Категории без порядка. | Цвета, формы, модели авто. | `=`, `≠` | Мода | - |
| **Порядковая** | Упорядоченные категории. | Размеры (S, M, L), уровень образования. | `>`, `<` | Медиана, мода | - |
| **Интервальная**| Равные интервалы, нет абсолютного нуля. | Температура в °C, даты. | `+`, `-` | Среднее, медиана, мода | Дисперсия |
| **Шкала отношений** | Есть абсолютный ноль. | Вес, рост, цена, возраст. | `*`, `/` | Среднее (все виды), медиана, мода | Все виды |

**Иерархия:** Каждая следующая шкала в таблице включает в себя свойства предыдущей и добавляет новые. Чем выше уровень шкалы, тем больше математических операций мы можем к ней применить и тем больше информации извлечь.

### Ключевые характеристики данных

1.  **Центральная тенденция (показатель "середины" данных):**
    *   **Мода:** Самое часто встречающееся значение (для всех шкал).
    *   **Медиана:** Значение, которое делит упорядоченные данные пополам (для порядковой и выше).
    *   **Среднее арифметическое:** Сумма всех значений, деленная на их количество (для интервальной и выше).

2.  **Отклонение (меры разброса данных):**
    *   **Дисперсия:** Средний квадрат отклонений значений от их среднего. Показывает, насколько данные "разбросаны".
    *   **Среднеквадратическое (стандартное) отклонение:** Корень из дисперсии. Более удобный для интерпретации показатель, так как измеряется в тех же единицах, что и сами данные.
        *   *Малое отклонение:* данные сгруппированы близко к среднему.
        *   *Большое отклонение:* данные сильно колеблются.

---

## 4. Основы теории вероятностей

*   **Вероятность события:** Числовая мера его правдоподобия, значение от 0 (невозможное событие) до 1 (достоверное событие).
*   **Случайная величина:** Характеристика, которая зависит от исхода случайного эксперимента (например, число выпавших орлов при 10 подбрасываниях монеты).
*   **Свойства вероятности:**
    *   `P(невозможное) = 0`
    *   `P(достоверное) = 1`
    *   Сумма вероятностей взаимоисключающих событий равна вероятности их объединения.

### Зависимость и условная вероятность
*   **Независимые события:** Знание об одном событии никак не влияет на вероятность другого.
*   **Зависимые события:** Используется формула условной вероятности `P(A|B)`, которая читается как "вероятность события A при условии, что событие B произошло".
*   **Применение:** Многие алгоритмы (например, **наивный байесовский классификатор**) строятся на предположении о независимости признаков. Поэтому на этапе подготовки данных важно проверять признаки на зависимость.

### Закон больших чисел
*   **Утверждение:** Если повторить случайный эксперимент очень много раз, то относительная частота наступления события будет стремиться к его истинной вероятности.
*   **Пример лектора:** Если подбросить монету 5 раз и получить 5 орлов, это ничего не значит. Но если подбросить ее 1000 раз, то доля орлов и решек будет очень близка к 0.5 (если монета "честная").

---

## 5. Распределения случайных величин

Распределение показывает, какие значения может принимать случайная величина и с какой вероятностью.

### Дискретные и непрерывные величины
*   **Дискретная:** Принимает конечное или счетное множество значений (число детей в семье, грань кубика).
*   **Непрерывная:** Принимает любое значение из некоторого интервала (рост человека, время ожидания автобуса).

### Базовые распределения

*   **Дискретные:**
    1.  **Биномиальное:** Описывает число "успехов" в серии независимых испытаний (например, сколько раз выпадет орел при N подбрасываниях).
    2.  **Распределение Пуассона:** Описывает число событий, происходящих за фиксированный интервал времени или на определенной площади (например, количество звонков в колл-центр за час).
*   **Непрерывные:**
    1.  **Нормальное (Гауссово):** Самое важное распределение. Описывает сумму множества независимых случайных факторов (рост, вес, результаты экзаменов).
    2.  **Экспоненциальное:** Моделирует случайные промежутки времени между событиями (например, время до поломки устройства).

Для непрерывных величин используется **функция плотности вероятности**, площадь под которой на заданном интервале и дает вероятность попадания величины в этот интервал.

---

## 6. Корреляция, выборки и смещения

### Корреляция
*   **Что показывает:** Коэффициент корреляции (например, Пирсона) показывает степень **линейной** зависимости между двумя величинами.
*   **Важное замечание лектора:** Корреляция, равная нулю, **не гарантирует** независимость. Это означает лишь отсутствие *линейной* связи. Зависимость может быть более сложной, нелинейной, и коэффициент Пирсона ее не покажет.

### Выборки
*   **Генеральная совокупность:** Все объекты, которые мы изучаем.
*   **Выборка:** Часть объектов из генеральной совокупности, которую мы непосредственно анализируем.
*   **Репрезентативность:** Главное требование к выборке. Она должна быть "микро-моделью" генеральной совокупности.
*   **Смещение выборки (Bias):** Систематическая ошибка, возникающая, когда выборка нерепрезентативна. Это один из главных источников ошибок в машинном обучении.
    *   **Пример лектора:** Если опрашивать о популярности напитка только студентов, результат будет смещенным и не будет отражать мнение всех возрастных групп.
