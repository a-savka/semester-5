# Конспект лекции: Методы искусственного интеллекта

## Введение

**Лектор:** Карпов Егор Константинович

**Основная цель дисциплины:** Изучение применения искусственного интеллекта для анализа данных. В рамках курса студенты научатся:
- Адекватно применять математические методы для предварительного анализа данных.
- Создавать и оценивать модели для решения задач интерпретации и прогнозирования.
- Оформлять и публично представлять результаты анализа данных.

**Практические занятия:** Будут проходить с использованием **Jupyter Notebook** или **Google Colab**.

---

## 1. Краткая история искусственного интеллекта

- **1952 год:** Создание первой модели, имитирующей нейроны человеческого мозга для распознавания геометрических фигур (круги, квадраты, треугольники).
- **Три большие эпохи развития:**
    1.  **Попытки повторить мозг:** Логические рассуждения, экспертные системы.
    2.  **Машинное обучение (Machine Learning):** С 1980-х по 2010-е годы. Активное развитие и применение в конкретных решениях.
    3.  **Глубокое обучение (Deep Learning):** Наше время. Появление комплексных, многослойных нейросетей и эффективных алгоритмов их обучения (например, большие языковые модели - LLM).

### Отличие Machine Learning от Deep Learning

| Аспект | Машинное обучение (Machine Learning) | Глубокое обучение (Deep Learning) |
| :--- | :--- | :--- |
| **Извлечение признаков (Feature Extraction)** | Выполняется **человеком**. Ученый или "учитель" вручную размечает данные (например, отмечает фото с котиками и без). Этот процесс трудоемкий и требует больших объемов качественно размеченных данных. | Выполняется **самой нейросетью**. Сеть самостоятельно находит ключевые признаки и закономерности в данных, что позволяет обходиться без ручной разметки человеком. |
| **Пример** | Человек создает датасет из 100 тыс. фотографий, отмечая, где есть кот, а где нет. | Нейросеть получает 100 тыс. фотографий, и сама учится отличать котов, находя общие для них признаки. |

---

## 2. Задачи машинного обучения

Машинное обучение применяется для решения следующих основных задач:

1.  **Классификация:** Определение принадлежности объекта к одному из классов.
    *   *Пример:* Является ли изображение кошкой или собакой? Разговаривает ли водитель по телефону во время движения?

2.  **Регрессия:** Предсказание числового значения.
    *   *Пример:* Прогнозирование стоимости квартиры в зависимости от рыночных условий.

3.  **Преобразование последовательности (Sequence-to-Sequence):** Преобразование одной последовательности в другую.
    *   *Пример:* Машинный перевод (текст на одном языке -> текст на другом), распознавание речи (звук -> текст).

4.  **Кластеризация:** Группировка схожих объектов без заранее известных меток.
    *   *Пример:* Анализ датасета с 50 млн строк и 50 тыс. параметров для обнаружения скрытых закономерностей, которые человек не в состоянии увидеть.

5.  **Понижение размерности:** Сокращение количества признаков (столбцов в таблице) до наиболее информативных, независимых компонент.
    *   *Пример:* Из 3000 параметров о поведении студентов в системе оставить только те, которые не зависят друг от друга, для дальнейшего анализа успеваемости.

---

## 3. Процесс машинного обучения

Процесс работы с данными и моделями можно разбить на следующие шаги:

1.  **Сбор данных:** Самый первый и важный этап. Данные могут быть получены из анкет, от датчиков, из компьютерных систем, лабораторных экспериментов и т.д. Важно планировать сбор и стремиться к получению **полных и достаточных** данных.

2.  **Подготовка данных:** Собранные данные почти всегда содержат ошибки, неточности, дубли.
    *   **Принцип "Мусор на входе, мусор на выходе":** Если использовать необработанные, "грязные" данные, результат работы модели также будет "мусорным".
    *   *Примеры очистки:* Приведение ответов "да/нет" к единому формату, удаление нелогичных значений (например, высота потолков 100 метров).

3.  **Обучение модели:**
    *   Выбор подходящего алгоритма.
    *   Процесс обучения (подача данных в модель).
    *   Регуляризация и тонкая настройка.

4.  **Анализ и оценка модели:** Проверка эффективности модели как с математической точки зрения, так и с точки зрения решения практической бизнес-задачи.

5.  **Внедрение:** Использование модели в реальных условиях.

6.  **Переобучение или дообучение:** Модель продолжает улучшаться на основе новых данных, полученных в ходе ее практического применения.
    *   *Пример:* Камера фиксации скорости ошибочно штрафовала машины в пробке. После анализа ошибки модель была дообучена, чтобы избегать подобных ситуаций.

---

## 4. Стандартный процесс исследования данных CRISP-DM

**CRISP-DM (Cross-Industry Standard Process for Data Mining)** — это международный стандарт, который позволяет системно подходить к анализу данных в любой сфере. Процесс цикличен и состоит из 6 этапов.

1.  **Понимание бизнеса (10% времени):**
    *   Определить бизнес-цели заказчика (даже если он сам их не до конца понимает).
    *   Оценить ресурсы, риски, требования и ограничения.
    *   Сформулировать цели анализа данных.
    *   Составить план проекта.

2.  **Понимание данных (20% времени):**
    *   Собрать исходные "сырые" данные.
    *   Описать и исследовать данные на наличие несоответствий.
    *   Проверить качество и достаточность данных для достижения бизнес-цели.

3.  **Подготовка данных (45% времени):**
    *   **Самый трудоемкий этап.**
    *   Отбор, очистка, форматирование и объединение данных.
    *   Создание датасета для обучения.
    *   Формулирование гипотез о решении проблемы.

4.  **Построение модели (10% времени):**
    *   Выбор техники моделирования.
    *   Подготовка тестов для оценки.
    *   Непосредственное построение (обучение) модели. Результатом является **файл с весами** (матрицами коэффициентов), который можно использовать в других программах.

5.  **Оценка (10% времени):**
    *   Анализ результатов с точки зрения достижения **бизнес-целей**.
    *   Оценка нерешенных задач.
    *   Описание полученных результатов на понятном для заказчика языке.
    *   Определение следующих шагов.

6.  **Внедрение (5% времени):**
    *   Разработка плана внедрения и сопровождения.
    *   Подготовка финального отчета и документации.
    *   Передача проекта.

---

## 5. Основы математики для анализа данных

### 5.1. Шкалы измерений

Прежде чем анализировать данные, нужно понять, как они измерены.

| Шкала | Описание | Пример | Допустимые операции |
| :--- | :--- | :--- | :--- |
| **Номинальная** | Классификация без порядка. | Цвета, формы, модели машин. | `=`, `≠` |
| **Порядковая** | Категории, которые можно упорядочить. | Размеры (S, M, L), уровень образования. | `>`, `<` |
| **Интервальная** | Упорядоченные значения с равными интервалами, но без абсолютного нуля. | Температура в °C. | `+`, `-` |
| **Шкала отношений** | Есть абсолютный ноль, интервалы равны. | Вес, рост. | `*`, `/` |

Чем выше уровень шкалы, тем больше математических операций можно применять и тем больше информации извлечь.

### 5.2. Важность визуализации: Квартет Энскомба

**Квартет Энскомба** — это четыре набора данных, у которых **абсолютно одинаковые** статистические характеристики (среднее, дисперсия, корреляция, коэффициенты регрессии), но при визуализации они выглядят совершенно по-разному.

![](https://upload.wikimedia.org/wikipedia/commons/thumb/b/b6/Anscombe.svg/500px-Anscombe.svg.png)

**Вывод:** Всегда нужно строить графики, чтобы не упустить скрытые закономерности, которые не видны в числовых характеристиках.

### 5.3. Основы теории вероятностей

- **Вероятность события:** Числовая мера его правдоподобия (от 0 до 1).
- **Закон больших чисел:** При многократном повторении эксперимента относительная частота события стремится к его истинной вероятности.
- **Распределения случайных величин:**
    - **Дискретные** (принимают конечные значения):
        - *Биномиальное:* число успехов в серии испытаний.
        - *Пуассона:* число событий за фиксированное время.
    - **Непрерывные** (принимают любое значение из интервала):
        - *Нормальное:* описывает сумму множества независимых факторов (рост, вес).
        - *Экспоненциальное:* моделирует случайные промежутки времени (время до поломки).
- **Корреляция:** Показывает **линейную** зависимость между величинами. Если корреляция равна 0, это не гарантирует полной независимости (связь может быть нелинейной).

### 5.4. Выборки и смещение

- **Генеральная совокупность:** Все объекты исследования (например, все жители города).
- **Выборка:** Часть объектов, выбранная из генеральной совокупности.
- **Репрезентативная выборка:** Выборка, которая максимально точно отражает свойства всей совокупности.
- **Смещение выборки (Bias):** Систематическая ошибка, возникающая из-за нерепрезентативности выборки. Это основной источник ошибок при обучении моделей.
    *   *Пример:* Обучить нейросеть предсказывать рост акций, используя только данные, где акции всегда росли. Такая модель всегда будет предсказывать рост, что неверно.

---

## 6. Задание для самостоятельной работы

Лектор предложил решить следующую задачу для лучшего понимания условной вероятности:

> *Сделайте скриншот этого задания и попробуйте его для себя к пятнице по желанию решить, чтоб лучше почувствовать, как у нас работают вероятности.*

*(В лекции был показан слайд с задачей, но его содержание не было озвучено. Для решения подобных задач рекомендуется повторить формулу условной вероятности).*

---

## 7. Итоги и инструменты

- Лекция носила обзорный и теоретический характер.
- Практического создания приложений и написания кода не было.
- Для дальнейшей работы рекомендованы инструменты:
    - **Jupyter Notebook**
    - **Google Colab**
